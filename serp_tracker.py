import os
import sys
import re
import json
import time
import sqlite3
import requests
import pandas as pd
from datetime import datetime, timedelta
from urllib.parse import quote_plus, urlparse
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from io import BytesIO
import base64
import threading
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver import ChromeOptions
from webdriver_manager.chrome import ChromeDriverManager
import urllib3
import logging

# –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –ª–æ–≥–æ–≤
logging.getLogger('selenium').setLevel(logging.WARNING)
logging.getLogger('webdriver_manager').setLevel(logging.WARNING)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class SERPTracker:
    def __init__(self, db_path="serp_tracker.db"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–π."""
        self.db_path = db_path
        self.init_database()
        
    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö —Å–∞–π—Ç–æ–≤
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS sites (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                domain TEXT UNIQUE NOT NULL,
                name TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS keywords (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                site_id INTEGER,
                keyword TEXT NOT NULL,
                search_engine TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (site_id) REFERENCES sites (id),
                UNIQUE(site_id, keyword, search_engine)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≤–µ—Ä–æ–∫
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS positions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                keyword_id INTEGER,
                position INTEGER,
                url TEXT,
                title TEXT,
                snippet TEXT,
                checked_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (keyword_id) REFERENCES keywords (id)
            )
        ''')
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ç–∞–±–ª–∏—Ü—ã positions
        self._update_positions_table(cursor)
        
        conn.commit()
        conn.close()
    
    def _update_positions_table(self, cursor):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã positions, –¥–æ–±–∞–≤–ª—è—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏."""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏
            cursor.execute("PRAGMA table_info(positions)")
            columns = [column[1] for column in cursor.fetchall()]
            
            print(f"üìã –¢–µ–∫—É—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ positions: {columns}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            if 'url' not in columns:
                cursor.execute("ALTER TABLE positions ADD COLUMN url TEXT")
                print("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'url' –≤ —Ç–∞–±–ª–∏—Ü—É positions")
            
            if 'title' not in columns:
                cursor.execute("ALTER TABLE positions ADD COLUMN title TEXT")
                print("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'title' –≤ —Ç–∞–±–ª–∏—Ü—É positions")
            
            if 'snippet' not in columns:
                cursor.execute("ALTER TABLE positions ADD COLUMN snippet TEXT")
                print("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'snippet' –≤ —Ç–∞–±–ª–∏—Ü—É positions")
            
            if 'checked_at' not in columns:
                cursor.execute("ALTER TABLE positions ADD COLUMN checked_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
                print("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'checked_at' –≤ —Ç–∞–±–ª–∏—Ü—É positions")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã positions: {e}")
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å, —Å–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –∑–∞–Ω–æ–≤–æ
            try:
                cursor.execute("DROP TABLE IF EXISTS positions")
                cursor.execute('''
                    CREATE TABLE positions (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        keyword_id INTEGER,
                        position INTEGER,
                        url TEXT,
                        title TEXT,
                        snippet TEXT,
                        checked_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (keyword_id) REFERENCES keywords (id)
                    )
                ''')
                print("‚úÖ –¢–∞–±–ª–∏—Ü–∞ positions –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π")
            except Exception as e2:
                print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–∏ —Ç–∞–±–ª–∏—Ü—ã: {e2}")
    
    def add_site(self, domain, name=None):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–∞–π—Ç –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute(
                "INSERT OR REPLACE INTO sites (domain, name) VALUES (?, ?)",
                (domain, name or domain)
            )
            site_id = cursor.lastrowid
            conn.commit()
            return site_id
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–∞–π—Ç–∞: {e}")
            return None
        finally:
            conn.close()
    
    def add_keyword(self, site_id, keyword, search_engine="google"):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute(
                "INSERT OR REPLACE INTO keywords (site_id, keyword, search_engine) VALUES (?, ?, ?)",
                (site_id, keyword, search_engine)
            )
            keyword_id = cursor.lastrowid
            conn.commit()
            return keyword_id
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞: {e}")
            return None
        finally:
            conn.close()
    
    def get_sites(self):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–∞–π—Ç–æ–≤."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("SELECT id, domain, name, created_at FROM sites ORDER BY created_at DESC")
        sites = cursor.fetchall()
        conn.close()
        
        return [{"id": row[0], "domain": row[1], "name": row[2], "created_at": row[3]} for row in sites]
    
    def get_keywords(self, site_id=None):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if site_id:
            cursor.execute(
                "SELECT k.id, k.keyword, k.search_engine, s.domain, k.created_at FROM keywords k JOIN sites s ON k.site_id = s.id WHERE k.site_id = ? ORDER BY k.created_at DESC",
                (site_id,)
            )
        else:
            cursor.execute(
                "SELECT k.id, k.keyword, k.search_engine, s.domain, k.created_at FROM keywords k JOIN sites s ON k.site_id = s.id ORDER BY k.created_at DESC"
            )
        
        keywords = cursor.fetchall()
        conn.close()
        
        return [{"id": row[0], "keyword": row[1], "search_engine": row[2], "domain": row[3], "created_at": row[4]} for row in keywords]
    
    def get_positions_history(self, keyword_id, days=30):
        """–ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute(
            "SELECT position, url, title, snippet, checked_at FROM positions WHERE keyword_id = ? AND checked_at >= datetime('now', '-{} days') ORDER BY checked_at ASC".format(days),
            (keyword_id,)
        )
        
        positions = cursor.fetchall()
        conn.close()
        
        return [{"position": row[0], "url": row[1], "title": row[2], "snippet": row[3], "checked_at": row[4]} for row in positions]
    
    def create_webdriver(self, headless=True):
        """–°–æ–∑–¥–∞–µ—Ç WebDriver –¥–ª—è –ø–æ–∏—Å–∫–∞."""
        options = ChromeOptions()
        if headless:
            options.add_argument("--headless=new")
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        
        try:
            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            return driver
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è WebDriver: {e}")
            return None
    
    def search_google(self, keyword, max_results=10):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤ Google."""
        driver = self.create_webdriver()
        if not driver:
            return []
        
        try:
            search_url = f"https://www.google.com/search?q={quote_plus(keyword)}&num={max_results}"
            driver.get(search_url)
            time.sleep(2)
            
            results = []
            search_results = driver.find_elements(By.CSS_SELECTOR, "div.g")
            
            for i, result in enumerate(search_results[:max_results], 1):
                try:
                    link_element = result.find_element(By.CSS_SELECTOR, "a")
                    url = link_element.get_attribute("href")
                    title_element = result.find_element(By.CSS_SELECTOR, "h3")
                    title = title_element.text if title_element else ""
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Å–Ω–∏–ø–ø–µ—Ç
                    snippet_element = result.find_element(By.CSS_SELECTOR, "div.VwiC3b")
                    snippet = snippet_element.text if snippet_element else ""
                    
                    if url and title:
                        results.append({
                            "position": i,
                            "url": url,
                            "title": title,
                            "snippet": snippet
                        })
                except Exception as e:
                    continue
            
            return results
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Google: {e}")
            return []
        finally:
            driver.quit()
    
    def search_yandex(self, keyword, max_results=10):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤ –Ø–Ω–¥–µ–∫—Å."""
        driver = self.create_webdriver()
        if not driver:
            return []
        
        try:
            search_url = f"https://yandex.ru/search/?text={quote_plus(keyword)}&numdoc={max_results}"
            driver.get(search_url)
            time.sleep(2)
            
            results = []
            search_results = driver.find_elements(By.CSS_SELECTOR, "li.serp-item")
            
            for i, result in enumerate(search_results[:max_results], 1):
                try:
                    link_element = result.find_element(By.CSS_SELECTOR, "a.link")
                    url = link_element.get_attribute("href")
                    title_element = result.find_element(By.CSS_SELECTOR, "a.link .organic__url-text")
                    title = title_element.text if title_element else ""
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Å–Ω–∏–ø–ø–µ—Ç
                    snippet_element = result.find_element(By.CSS_SELECTOR, ".organic__content-wrapper .text")
                    snippet = snippet_element.text if snippet_element else ""
                    
                    if url and title:
                        results.append({
                            "position": i,
                            "url": url,
                            "title": title,
                            "snippet": snippet
                        })
                except Exception as e:
                    continue
            
            return results
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –Ø–Ω–¥–µ–∫—Å: {e}")
            return []
        finally:
            driver.quit()
    
    def check_position(self, keyword, domain, search_engine="google"):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–∑–∏—Ü–∏—é —Å–∞–π—Ç–∞ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É."""
        if search_engine.lower() == "google":
            results = self.search_google(keyword)
        elif search_engine.lower() == "yandex":
            results = self.search_yandex(keyword)
        else:
            return None
        
        # –ò—â–µ–º —Å–∞–π—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
        for result in results:
            if domain in result["url"]:
                return result
        
        return None
    
    def track_keyword(self, keyword_id, keyword, domain, search_engine="google"):
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –ø–æ–∑–∏—Ü–∏—é –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
        result = self.check_position(keyword, domain, search_engine)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            if result:
                cursor.execute(
                    "INSERT INTO positions (keyword_id, position, url, title, snippet) VALUES (?, ?, ?, ?, ?)",
                    (keyword_id, result["position"], result["url"], result["title"], result["snippet"])
                )
            else:
                # –ï—Å–ª–∏ —Å–∞–π—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–æ–ø-10, –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é 0
                cursor.execute(
                    "INSERT INTO positions (keyword_id, position, url, title, snippet) VALUES (?, ?, ?, ?, ?)",
                    (keyword_id, 0, "", "", "")
                )
            
            conn.commit()
            return result
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–∏: {e}")
            return None
        finally:
            conn.close()
    
    def track_all_keywords(self, site_id=None):
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞."""
        keywords = self.get_keywords(site_id)
        results = []
        
        for kw in keywords:
            site = self.get_site_by_id(kw["id"])
            if site:
                result = self.track_keyword(kw["id"], kw["keyword"], site["domain"], kw["search_engine"])
                results.append({
                    "keyword": kw["keyword"],
                    "search_engine": kw["search_engine"],
                    "result": result
                })
        
        return results
    
    def get_site_by_id(self, keyword_id):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–∞–π—Ç –ø–æ ID –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute(
            "SELECT s.id, s.domain, s.name FROM sites s JOIN keywords k ON s.id = k.site_id WHERE k.id = ?",
            (keyword_id,)
        )
        
        row = cursor.fetchone()
        conn.close()
        
        if row:
            return {"id": row[0], "domain": row[1], "name": row[2]}
        return None
    
    def generate_position_chart(self, keyword_id, days=30):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –¥–≤–∏–∂–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π."""
        history = self.get_positions_history(keyword_id, days)
        
        if not history:
            return None
        
        dates = [datetime.strptime(pos["checked_at"], "%Y-%m-%d %H:%M:%S") for pos in history]
        positions = [pos["position"] for pos in history]
        
        plt.figure(figsize=(12, 6))
        plt.plot(dates, positions, marker='o', linewidth=2, markersize=6)
        plt.gca().invert_yaxis()  # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ—Å—å Y (–ª—É—á—à–∏–µ –ø–æ–∑–∏—Ü–∏–∏ —Å–≤–µ—Ä—Ö—É)
        
        plt.title("–î–≤–∏–∂–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏", fontsize=14, fontweight='bold')
        plt.xlabel("–î–∞—Ç–∞", fontsize=12)
        plt.ylabel("–ü–æ–∑–∏—Ü–∏—è", fontsize=12)
        plt.grid(True, alpha=0.3)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç
        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d.%m'))
        plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=max(1, len(dates)//10)))
        plt.xticks(rotation=45)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è –ª—É—á—à–∏—Ö –∏ —Ö—É–¥—à–∏—Ö –ø–æ–∑–∏—Ü–∏–π
        if positions:
            best_pos = min(positions)
            worst_pos = max(positions)
            best_date = dates[positions.index(best_pos)]
            worst_date = dates[positions.index(worst_pos)]
            
            plt.annotate(f'–õ—É—á—à–∞—è: {best_pos}', xy=(best_date, best_pos), 
                        xytext=(10, 10), textcoords='offset points',
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='green', alpha=0.7),
                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
            
            plt.annotate(f'–•—É–¥—à–∞—è: {worst_pos}', xy=(worst_date, worst_pos), 
                        xytext=(10, -10), textcoords='offset points',
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='red', alpha=0.7),
                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
        
        plt.tight_layout()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ base64
        buffer = BytesIO()
        plt.savefig(buffer, format='png', dpi=300, bbox_inches='tight')
        buffer.seek(0)
        plt.close()
        
        return base64.b64encode(buffer.getvalue()).decode()
    
    def export_to_excel(self, site_id=None, filename=None):
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ Excel."""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"serp_report_{timestamp}.xlsx"
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        keywords = self.get_keywords(site_id)
        
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            # –õ–∏—Å—Ç —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
            keywords_df = pd.DataFrame(keywords)
            keywords_df.to_excel(writer, sheet_name='–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞', index=False)
            
            # –õ–∏—Å—Ç —Å –ø–æ–∑–∏—Ü–∏—è–º–∏
            all_positions = []
            for kw in keywords:
                history = self.get_positions_history(kw["id"])
                for pos in history:
                    all_positions.append({
                        "–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ": kw["keyword"],
                        "–ü–æ–∏—Å–∫–æ–≤–∏–∫": kw["search_engine"],
                        "–î–æ–º–µ–Ω": kw["domain"],
                        "–ü–æ–∑–∏—Ü–∏—è": pos["position"],
                        "URL": pos["url"],
                        "–ó–∞–≥–æ–ª–æ–≤–æ–∫": pos["title"],
                        "–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏": pos["checked_at"]
                    })
            
            positions_df = pd.DataFrame(all_positions)
            positions_df.to_excel(writer, sheet_name='–ü–æ–∑–∏—Ü–∏–∏', index=False)
            
            # –õ–∏—Å—Ç —Å–æ —Å–≤–æ–¥–∫–æ–π
            summary_data = []
            for kw in keywords:
                history = self.get_positions_history(kw["id"])
                if history:
                    current_pos = history[-1]["position"]
                    best_pos = min(pos["position"] for pos in history if pos["position"] > 0)
                    worst_pos = max(pos["position"] for pos in history)
                    
                    summary_data.append({
                        "–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ": kw["keyword"],
                        "–ü–æ–∏—Å–∫–æ–≤–∏–∫": kw["search_engine"],
                        "–î–æ–º–µ–Ω": kw["domain"],
                        "–¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è": current_pos,
                        "–õ—É—á—à–∞—è –ø–æ–∑–∏—Ü–∏—è": best_pos,
                        "–•—É–¥—à–∞—è –ø–æ–∑–∏—Ü–∏—è": worst_pos,
                        "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≤–µ—Ä–æ–∫": len(history)
                    })
            
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, sheet_name='–°–≤–æ–¥–∫–∞', index=False)
        
        return filename
    
    def get_statistics(self, site_id=None):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–æ–∑–∏—Ü–∏—è–º."""
        keywords = self.get_keywords(site_id)
        stats = {
            "total_keywords": len(keywords),
            "google_keywords": len([kw for kw in keywords if kw["search_engine"] == "google"]),
            "yandex_keywords": len([kw for kw in keywords if kw["search_engine"] == "yandex"]),
            "top_3": 0,
            "top_10": 0,
            "not_found": 0
        }
        
        for kw in keywords:
            history = self.get_positions_history(kw["id"], days=1)  # –¢–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            if history:
                last_position = history[-1]["position"]
                if last_position == 0:
                    stats["not_found"] += 1
                elif last_position <= 3:
                    stats["top_3"] += 1
                elif last_position <= 10:
                    stats["top_10"] += 1
        
        return stats

def run_serp_tracking(keywords_list, domain, search_engines=["google", "yandex"], update_callback=None):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç—Ä–µ–∫–∏–Ω–≥ –ø–æ–∑–∏—Ü–∏–π –¥–ª—è —Å–ø–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤."""
    tracker = SERPTracker()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–∞–π—Ç
    site_id = tracker.add_site(domain)
    if not site_id:
        return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Å–∞–π—Ç"}
    
    results = []
    total_keywords = len(keywords_list) * len(search_engines)
    current = 0
    
    for keyword in keywords_list:
        for engine in search_engines:
            try:
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
                keyword_id = tracker.add_keyword(site_id, keyword, engine)
                if keyword_id:
                    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é
                    result = tracker.track_keyword(keyword_id, keyword, domain, engine)
                    
                    results.append({
                        "keyword": keyword,
                        "search_engine": engine,
                        "position": result["position"] if result else 0,
                        "url": result["url"] if result else "",
                        "title": result["title"] if result else "",
                        "status": "success"
                    })
                else:
                    results.append({
                        "keyword": keyword,
                        "search_engine": engine,
                        "position": 0,
                        "url": "",
                        "title": "",
                        "status": "error"
                    })
                
                current += 1
                if update_callback:
                    update_callback(current, total_keywords, f"–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: {keyword} –≤ {engine}")
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(2)
                
            except Exception as e:
                results.append({
                    "keyword": keyword,
                    "search_engine": engine,
                    "position": 0,
                    "url": "",
                    "title": "",
                    "status": f"error: {str(e)}"
                })
                current += 1
    
    return {
        "site_id": site_id,
        "results": results,
        "statistics": tracker.get_statistics(site_id)
    }

def run_detailed_site_analysis(domain, search_engines=["google", "yandex"], update_callback=None):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–∞–π—Ç–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–∏—Å–∫–æ–º –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏ —Ç—Ä–µ–∫–∏–Ω–≥–æ–º –ø–æ–∑–∏—Ü–∏–π."""
    tracker = SERPTracker()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–∞–π—Ç
    site_id = tracker.add_site(domain)
    if not site_id:
        return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Å–∞–π—Ç"}
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–º–µ–Ω–∞
    auto_keywords = generate_keywords_from_domain(domain)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    base_keywords = [
        domain.replace('.com', '').replace('.ru', '').replace('.org', '').replace('.net', ''),
        domain,
        f"—Å–∞–π—Ç {domain}",
        f"–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç {domain}"
    ]
    
    all_keywords = list(set(base_keywords + auto_keywords))
    
    results = []
    detailed_results = []
    total_keywords = len(all_keywords) * len(search_engines)
    current = 0
    
    for keyword in all_keywords:
        for engine in search_engines:
            try:
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
                keyword_id = tracker.add_keyword(site_id, keyword, engine)
                if keyword_id:
                    # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∏—Å–∫–æ–≤–æ–π –≤—ã–¥–∞—á–µ
                    search_results = get_detailed_search_results(keyword, domain, engine, tracker)
                    
                    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é
                    result = tracker.track_keyword(keyword_id, keyword, domain, engine)
                    
                    position = result["position"] if result else 0
                    url = result["url"] if result else ""
                    title = result["title"] if result else ""
                    
                    results.append({
                        "keyword": keyword,
                        "search_engine": engine,
                        "position": position,
                        "url": url,
                        "title": title,
                        "status": "success"
                    })
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                    detailed_results.append({
                        "keyword": keyword,
                        "search_engine": engine,
                        "position": position,
                        "url": url,
                        "title": title,
                        "snippet": result.get("snippet", "") if result else "",
                        "search_results": search_results,
                        "status": "success"
                    })
                else:
                    results.append({
                        "keyword": keyword,
                        "search_engine": engine,
                        "position": 0,
                        "url": "",
                        "title": "",
                        "status": "error"
                    })
                
                current += 1
                if update_callback:
                    update_callback(current, total_keywords, f"–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: '{keyword}' –≤ {engine}")
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(2)
                
            except Exception as e:
                results.append({
                    "keyword": keyword,
                    "search_engine": engine,
                    "position": 0,
                    "url": "",
                    "title": "",
                    "status": f"error: {str(e)}"
                })
                current += 1
    
    return {
        "site_id": site_id,
        "domain": domain,
        "keywords_checked": all_keywords,
        "results": results,
        "detailed_results": detailed_results,
        "statistics": tracker.get_statistics(site_id),
        "charts": generate_charts_for_site(site_id, tracker)
    }

def generate_keywords_from_domain(domain):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–º–µ–Ω–∞."""
    # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –¥–æ–º–µ–Ω–∞
    clean_domain = domain.replace('.com', '').replace('.ru', '').replace('.org', '').replace('.net', '')
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
    words = clean_domain.split('.')
    keywords = []
    
    for word in words:
        if len(word) > 2:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
            keywords.extend([
                word,
                f"{word} –∫—É–ø–∏—Ç—å",
                f"{word} –∑–∞–∫–∞–∑–∞—Ç—å",
                f"{word} —Ü–µ–Ω–∞",
                f"{word} –æ—Ç–∑—ã–≤—ã",
                f"{word} –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç"
            ])
    
    return keywords[:20]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤

def get_detailed_search_results(keyword, domain, search_engine, tracker):
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∏—Å–∫–æ–≤–æ–π –≤—ã–¥–∞—á–µ."""
    try:
        if search_engine == "google":
            results = tracker.search_google(keyword, max_results=10)
        elif search_engine == "yandex":
            results = tracker.search_yandex(keyword, max_results=10)
        else:
            return []
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –Ω–∞—à–µ–≥–æ —Å–∞–π—Ç–∞
        our_position = 0
        our_result = None
        
        for i, result in enumerate(results, 1):
            if domain in result.get("url", ""):
                our_position = i
                our_result = result
                break
        
        return {
            "our_position": our_position,
            "our_result": our_result,
            "all_results": results,
            "total_results": len(results)
        }
        
    except Exception as e:
        return {
            "our_position": 0,
            "our_result": None,
            "all_results": [],
            "total_results": 0,
            "error": str(e)
        }

def generate_charts_for_site(site_id, tracker):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è —Å–∞–π—Ç–∞."""
    try:
        keywords = tracker.get_keywords(site_id)
        charts = {}
        
        for kw in keywords:
            chart_data = tracker.generate_position_chart(kw["id"], days=30)
            if chart_data:
                charts[f"{kw['keyword']}_{kw['search_engine']}"] = chart_data
        
        return charts
    except Exception as e:
        return {"error": str(e)} 