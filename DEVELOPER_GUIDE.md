# üõ†Ô∏è –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞ SEO Analyzer

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–û–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞](#–æ–±–∑–æ—Ä-–ø—Ä–æ–µ–∫—Ç–∞)
2. [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è](#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è)
3. [–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞](#—É—Å—Ç–∞–Ω–æ–≤–∫–∞-–∏-–Ω–∞—Å—Ç—Ä–æ–π–∫–∞)
4. [–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–¥–∞](#—Å—Ç—Ä—É–∫—Ç—É—Ä–∞-–∫–æ–¥–∞)
5. [–û—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥—É–ª–∏](#–æ—Å–Ω–æ–≤–Ω—ã–µ-–º–æ–¥—É–ª–∏)
6. [–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö](#–±–∞–∑–∞-–¥–∞–Ω–Ω—ã—Ö)
7. [API –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏](#api-–∏-–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏)
8. [–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ](#—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
9. [–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ](#—Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ)
10. [–£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫](#—É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ-–Ω–µ–ø–æ–ª–∞–¥–æ–∫)
11. [–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é](#—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏-–ø–æ-—É–ª—É—á—à–µ–Ω–∏—é)

---

## üéØ –û–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

SEO Analyzer - —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–µ–±-—Å–∞–π—Ç–æ–≤ —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏:

- SEO-–∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü
- –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π –≤ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
- –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤

### –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

- **Frontend**: Flet (Python UI framework)
- **Backend**: Python 3.8+
- **–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö**: SQLite
- **–í–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥**: Selenium + BeautifulSoup
- **–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö**: Pandas, Matplotlib
- **–û—Ç—á–µ—Ç—ã**: Excel (openpyxl), Word (python-docx)

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤

```
SEO new/
‚îú‚îÄ‚îÄ main.py                    # –ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
‚îú‚îÄ‚îÄ serp_tracker.py            # –ë–∞–∑–æ–≤—ã–π SERP —Ç—Ä–µ–∫–µ—Ä
‚îú‚îÄ‚îÄ serp_tracker_advanced.py   # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π SERP —Ç—Ä–µ–∫–µ—Ä
‚îú‚îÄ‚îÄ requirements.txt           # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ assets/                    # –†–µ—Å—É—Ä—Å—ã (–∏–∫–æ–Ω–∫–∏, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
‚îú‚îÄ‚îÄ reports/                   # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç—ã
‚îú‚îÄ‚îÄ screenshots/              # –°–∫—Ä–∏–Ω—à–æ—Ç—ã —Å—Ç—Ä–∞–Ω–∏—Ü
‚îî‚îÄ‚îÄ *.db                      # –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö SQLite
```

### –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

#### 1. –ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å (main.py)

- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
- **–ö–ª—é—á–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏**:
  - `run_test()` - –ø–æ–ª–Ω—ã–π SEO-–∞–Ω–∞–ª–∏–∑
  - `run_links_test()` - –∞–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ–∫
  - `analyze_keywords()` - –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
  - `check_seo_files()` - –ø—Ä–æ–≤–µ—Ä–∫–∞ robots.txt –∏ sitemap.xml

#### 2. SERP –¢—Ä–µ–∫–µ—Ä (serp_tracker.py)

- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π –≤ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö
- **–ö–ª—é—á–µ–≤—ã–µ –∫–ª–∞—Å—Å—ã**:
  - `SERPTracker` - –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å —Ç—Ä–µ–∫–µ—Ä–∞
  - `run_serp_tracking()` - —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞
  - `run_detailed_site_analysis()` - –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–∞–π—Ç–∞

#### 3. WebDriver Manager

- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±—Ä–∞—É–∑–µ—Ä–æ–º –¥–ª—è —Å–∫—Ä–∞–ø–∏–Ω–≥–∞
- **–§—É–Ω–∫—Ü–∏–∏**:
  - `create_webdriver()` - —Å–æ–∑–¥–∞–Ω–∏–µ –¥—Ä–∞–π–≤–µ—Ä–∞
  - –û–±—Ö–æ–¥ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ –∏ –∫–∞–ø—á–∏
  - –†–æ—Ç–∞—Ü–∏—è User-Agent

---

## ‚öôÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

### –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **–û–°**: Windows 10/11
- **Python**: 3.8+
- **RAM**: 4 GB (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 8 GB)
- **–ú–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ**: 500 MB
- **–ò–Ω—Ç–µ—Ä–Ω–µ—Ç**: —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–∞–π—Ç–æ–≤

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone <repository-url>
cd seo-analyzer

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements.txt
```

### –ö–ª—é—á–µ–≤—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```python
# –û—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
flet                    # UI framework
selenium               # –í–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥
webdriver-manager      # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥—Ä–∞–π–≤–µ—Ä–∞–º–∏
requests               # HTTP –∑–∞–ø—Ä–æ—Å—ã
beautifulsoup4         # –ü–∞—Ä—Å–∏–Ω–≥ HTML
pandas                 # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
openpyxl               # Excel –æ—Ç—á–µ—Ç—ã
python-docx            # Word –æ—Ç—á–µ—Ç—ã
matplotlib             # –ì—Ä–∞—Ñ–∏–∫–∏
seaborn                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

#### 1. –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.env`:

```env
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
DB_PATH=serp_tracker.db

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ API (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è)
GOOGLE_API_KEY=your_api_key
YANDEX_API_KEY=your_api_key

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
LOG_LEVEL=INFO
LOG_FILE=seo_log.txt
```

#### 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ChromeDriver

```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
from webdriver_manager.chrome import ChromeDriverManager
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))

# –†—É—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞
# 1. –°–∫–∞—á–∞–π—Ç–µ ChromeDriver —Å https://chromedriver.chromium.org/
# 2. –î–æ–±–∞–≤—å—Ç–µ –ø—É—Ç—å –≤ PATH –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –≤ –∫–æ–¥–µ
```

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–¥–∞

### –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ main.py

#### 1. –§—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞

```python
def run_test(site_url, summary_area, page, progress_bar, ignore_ssl, target_keywords):
    """–ü–æ–ª–Ω—ã–π SEO-–∞–Ω–∞–ª–∏–∑ —Å–∞–π—Ç–∞"""
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
    # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç–∞-—Ç–µ–≥–æ–≤
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Å—ã–ª–æ–∫
    # –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞

def analyze_keywords(driver, site_url, target_keywords):
    """–ê–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å —É—á–µ—Ç–æ–º —Å–∫–ª–æ–Ω–µ–Ω–∏–π"""
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
    # –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç—ã
    # –ê–Ω–∞–ª–∏–∑ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∫–ª–æ–Ω–µ–Ω–∏–π

def check_seo_files(site_url, ignore_ssl):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ robots.txt –∏ sitemap.xml"""
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
    # –ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
    # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
```

#### 2. –§—É–Ω–∫—Ü–∏–∏ WebDriver

```python
def create_webdriver(ignore_ssl=False, window_size=None, anti_bot_mode=False):
    """–°–æ–∑–¥–∞–Ω–∏–µ WebDriver —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ü–∏–π Chrome
    # –û–±—Ö–æ–¥ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
    # –†–æ—Ç–∞—Ü–∏—è User-Agent
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∫—Å–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)

def check_site_accessibility(site_url, ignore_ssl=False):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–∞–π—Ç–∞"""
    # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–æ—Å—Ç—É–ø–∞
    # –û–±—Ö–æ–¥ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
    # –ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–æ–≤
```

#### 3. –§—É–Ω–∫—Ü–∏–∏ –æ—Ç—á–µ—Ç–æ–≤

```python
def save_results(site_url, log_content, summary_content, report_type='full', format='excel'):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
    # –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
    # –≠–∫—Å–ø–æ—Ä—Ç –≤ Excel/Word

def generate_report(summary, site_url, report_type='full', format='txt'):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤"""
    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
```

### –û—Å–Ω–æ–≤–Ω—ã–µ –∫–ª–∞—Å—Å—ã serp_tracker.py

#### 1. –ö–ª–∞—Å—Å SERPTracker

```python
class SERPTracker:
    def __init__(self, db_path="serp_tracker.db"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–∞"""
        self.db_path = db_path
        self.init_database()

    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã

    def add_site(self, domain, name=None):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∞–π—Ç–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è"""
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–æ–º–µ–Ω–∞
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
        # –í–æ–∑–≤—Ä–∞—Ç ID

    def add_keyword(self, site_id, keyword, search_engine="google"):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
        # –°–≤—è–∑—å —Å —Å–∞–π—Ç–æ–º

    def track_keyword(self, keyword_id, keyword, domain, search_engine="google"):
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É"""
        # –ü–æ–∏—Å–∫ –≤ Google/Yandex
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏
```

#### 2. –§—É–Ω–∫—Ü–∏–∏ –ø–æ–∏—Å–∫–∞

```python
def search_google(self, keyword, max_results=10):
    """–ü–æ–∏—Å–∫ –≤ Google"""
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
    # –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π

def search_yandex(self, keyword, max_results=10):
    """–ü–æ–∏—Å–∫ –≤ Yandex"""
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
    # –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π
```

---

## üóÑÔ∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü

#### 1. –¢–∞–±–ª–∏—Ü–∞ sites

```sql
CREATE TABLE sites (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    domain TEXT UNIQUE NOT NULL,
    name TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 2. –¢–∞–±–ª–∏—Ü–∞ keywords

```sql
CREATE TABLE keywords (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    site_id INTEGER,
    keyword TEXT NOT NULL,
    search_engine TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (site_id) REFERENCES sites (id),
    UNIQUE(site_id, keyword, search_engine)
);
```

#### 3. –¢–∞–±–ª–∏—Ü–∞ positions

```sql
CREATE TABLE positions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    keyword_id INTEGER,
    position INTEGER,
    url TEXT,
    title TEXT,
    snippet TEXT,
    checked_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (keyword_id) REFERENCES keywords (id)
);
```

### –û–ø–µ—Ä–∞—Ü–∏–∏ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö

#### 1. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ

```python
import sqlite3

def get_connection():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î"""
    return sqlite3.connect(self.db_path)

def close_connection(conn):
    """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
    conn.close()
```

#### 2. CRUD –æ–ø–µ—Ä–∞—Ü–∏–∏

```python
def add_record(self, table, data):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏"""
    conn = self.get_connection()
    cursor = conn.cursor()

    columns = ', '.join(data.keys())
    placeholders = ', '.join(['?' for _ in data])
    query = f"INSERT INTO {table} ({columns}) VALUES ({placeholders})"

    cursor.execute(query, list(data.values()))
    conn.commit()
    conn.close()

    return cursor.lastrowid

def get_records(self, table, conditions=None):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π"""
    conn = self.get_connection()
    cursor = conn.cursor()

    query = f"SELECT * FROM {table}"
    if conditions:
        query += f" WHERE {conditions}"

    cursor.execute(query)
    results = cursor.fetchall()
    conn.close()

    return results
```

---

## üîå API –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø–æ–∏—Å–∫–æ–≤—ã–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏

#### 1. Google Search API

```python
def search_google_api(keyword, api_key):
    """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Google Search API"""
    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        'key': api_key,
        'cx': 'your_search_engine_id',
        'q': keyword,
        'num': 10
    }

    response = requests.get(url, params=params)
    return response.json()
```

#### 2. Yandex Search API

```python
def search_yandex_api(keyword, api_key):
    """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Yandex Search API"""
    url = "https://yandex.ru/search/xml"
    params = {
        'user': 'your_username',
        'key': api_key,
        'query': keyword,
        'maxpassages': 10
    }

    response = requests.get(url, params=params)
    return response.text
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–µ—Ä–≤–∏—Å–∞–º–∏

#### 1. Google Analytics

```python
def get_analytics_data(property_id, start_date, end_date):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Analytics"""
    from google.oauth2 import service_account
    from googleapiclient.discovery import build

    credentials = service_account.Credentials.from_service_account_file(
        'path/to/service-account-key.json',
        scopes=['https://www.googleapis.com/auth/analytics.readonly']
    )

    analytics = build('analyticsreporting', 'v4', credentials=credentials)

    response = analytics.reports().batchGet(
        body={
            'reportRequests': [
                {
                    'viewId': property_id,
                    'dateRanges': [{'startDate': start_date, 'endDate': end_date}],
                    'metrics': [{'expression': 'ga:sessions'}],
                    'dimensions': [{'name': 'ga:date'}]
                }
            ]
        }
    ).execute()

    return response
```

#### 2. Google Search Console

```python
def get_search_console_data(site_url, start_date, end_date):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Search Console"""
    from google.oauth2 import service_account
    from googleapiclient.discovery import build

    credentials = service_account.Credentials.from_service_account_file(
        'path/to/service-account-key.json',
        scopes=['https://www.googleapis.com/auth/webmasters.readonly']
    )

    service = build('searchconsole', 'v1', credentials=credentials)

    request = {
        'startDate': start_date,
        'endDate': end_date,
        'dimensions': ['query', 'page'],
        'rowLimit': 1000
    }

    response = service.searchAnalytics().query(
        siteUrl=site_url,
        body=request
    ).execute()

    return response
```

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –¢–∏–ø—ã —Ç–µ—Å—Ç–æ–≤

#### 1. –ú–æ–¥—É–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã

```python
import unittest
from unittest.mock import Mock, patch

class TestSERPTracker(unittest.TestCase):
    def setUp(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        self.tracker = SERPTracker(":memory:")

    def test_add_site(self):
        """–¢–µ—Å—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–∞–π—Ç–∞"""
        site_id = self.tracker.add_site("example.com", "Test Site")
        self.assertIsNotNone(site_id)

        sites = self.tracker.get_sites()
        self.assertEqual(len(sites), 1)
        self.assertEqual(sites[0]['domain'], "example.com")

    def test_add_keyword(self):
        """–¢–µ—Å—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞"""
        site_id = self.tracker.add_site("example.com")
        keyword_id = self.tracker.add_keyword(site_id, "test keyword")

        self.assertIsNotNone(keyword_id)

        keywords = self.tracker.get_keywords(site_id)
        self.assertEqual(len(keywords), 1)
        self.assertEqual(keywords[0]['keyword'], "test keyword")

    @patch('requests.get')
    def test_search_google(self, mock_get):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –≤ Google"""
        # –ú–æ–∫–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç Google
        mock_response = Mock()
        mock_response.text = "<html>...</html>"
        mock_get.return_value = mock_response

        results = self.tracker.search_google("test keyword")
        self.assertIsInstance(results, list)
```

#### 2. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã

```python
class TestIntegration(unittest.TestCase):
    def test_full_analysis_workflow(self):
        """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞
        site_url = "https://example.com"

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
        with patch('selenium.webdriver.Chrome') as mock_driver:
            mock_driver.return_value.page_source = "<html>...</html>"

            result = run_test(site_url, Mock(), Mock(), Mock(), False, "")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞
            self.assertIsNotNone(result)

    def test_serp_tracking_workflow(self):
        """–¢–µ—Å—Ç –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π"""
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞
        keywords = ["test keyword"]
        domain = "example.com"

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
        with patch('requests.get') as mock_get:
            mock_response = Mock()
            mock_response.text = "<html>...</html>"
            mock_get.return_value = mock_response

            result = run_serp_tracking(keywords, domain)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞
            self.assertIsNotNone(result)
```

#### 3. –¢–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```python
import time
import cProfile
import pstats

class TestPerformance(unittest.TestCase):
    def test_analysis_performance(self):
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞"""
        site_url = "https://example.com"

        # –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
        profiler = cProfile.Profile()
        profiler.enable()

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞
        run_test(site_url, Mock(), Mock(), Mock(), False, "")

        profiler.disable()

        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        stats = pstats.Stats(profiler)
        stats.sort_stats('cumulative')

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        total_time = stats.total_tt
        self.assertLess(total_time, 30)  # –ù–µ –±–æ–ª–µ–µ 30 —Å–µ–∫—É–Ω–¥

    def test_memory_usage(self):
        """–¢–µ—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        import psutil
        import os

        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–π
        for i in range(10):
            run_test(f"https://example{i}.com", Mock(), Mock(), Mock(), False, "")

        final_memory = process.memory_info().rss
        memory_increase = final_memory - initial_memory

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ (–Ω–µ –±–æ–ª–µ–µ 100MB)
        self.assertLess(memory_increase, 100 * 1024 * 1024)
```

### –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤

```bash
# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤
python -m unittest discover tests

# –ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
python -m unittest tests.test_serp_tracker

# –ó–∞–ø—É—Å–∫ —Å –ø–æ–∫—Ä—ã—Ç–∏–µ–º
coverage run -m unittest discover tests
coverage report
coverage html
```

---

## üöÄ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

### –°–æ–∑–¥–∞–Ω–∏–µ –∏—Å–ø–æ–ª–Ω—è–µ–º–æ–≥–æ —Ñ–∞–π–ª–∞

#### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyInstaller

```bash
pip install pyinstaller
```

#### 2. –°–æ–∑–¥–∞–Ω–∏–µ spec —Ñ–∞–π–ª–∞

```python
# seo_analyzer.spec
a = Analysis(
    ['main.py'],
    pathex=[],
    binaries=[],
    datas=[
        ('assets', 'assets'),
        ('requirements.txt', '.'),
        ('README.md', '.')
    ],
    hiddenimports=[
        'selenium',
        'webdriver_manager',
        'flet',
        'pandas',
        'openpyxl',
        'docx'
    ],
    hookspath=[],
    hooksconfig={},
    runtime_hooks=[],
    excludes=[],
    win_no_prefer_redirects=False,
    win_private_assemblies=False,
    cipher=None,
    noarchive=False,
)

pyz = PYZ(a.pure, a.zipped_data, cipher=a.cipher)

exe = EXE(
    pyz,
    a.scripts,
    a.binaries,
    a.zipfiles,
    a.datas,
    [],
    name='SEO_Analyzer',
    debug=False,
    bootloader_ignore_signals=False,
    strip=False,
    upx=True,
    upx_exclude=[],
    runtime_tmpdir=None,
    console=False,
    disable_windowed_traceback=False,
    argv_emulation=False,
    target_arch=None,
    codesign_identity=None,
    entitlements_file=None,
    icon='assets/seo_icon.ico'
)
```

#### 3. –°–±–æ—Ä–∫–∞

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ exe —Ñ–∞–π–ª–∞
pyinstaller seo_analyzer.spec

# –ò–ª–∏ –ø—Ä–æ—Å—Ç–∞—è —Å–±–æ—Ä–∫–∞
pyinstaller --onefile --windowed --icon=assets/seo_icon.ico main.py
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CI/CD

#### 1. GitHub Actions

```yaml
# .github/workflows/build.yml
name: Build and Test

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest coverage

      - name: Run tests
        run: |
          python -m pytest tests/ --cov=. --cov-report=xml

      - name: Upload coverage
        uses: codecov/codecov-action@v1
        with:
          file: ./coverage.xml

  build:
    needs: test
    runs-on: windows-latest

    steps:
      - uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pyinstaller

      - name: Build executable
        run: |
          pyinstaller --onefile --windowed --icon=assets/seo_icon.ico main.py

      - name: Upload artifact
        uses: actions/upload-artifact@v2
        with:
          name: SEO_Analyzer
          path: dist/
```

#### 2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ

```python
# auto_updater.py
import requests
import os
import sys
from packaging import version

def check_for_updates():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π"""
    current_version = "2.0.0"

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤–µ—Ä—Å–∏–∏
    response = requests.get("https://api.github.com/repos/username/seo-analyzer/releases/latest")
    latest_version = response.json()["tag_name"]

    if version.parse(latest_version) > version.parse(current_version):
        return True, latest_version

    return False, current_version

def download_update(version):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
    url = f"https://github.com/username/seo-analyzer/releases/download/{version}/SEO_Analyzer.exe"

    response = requests.get(url, stream=True)

    with open("SEO_Analyzer_new.exe", "wb") as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)

    return "SEO_Analyzer_new.exe"

def install_update():
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
    import subprocess

    # –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    subprocess.Popen(["updater.exe", "SEO_Analyzer_new.exe"])
    sys.exit(0)
```

---

## üîß –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

#### 1. –û—à–∏–±–∫–∏ WebDriver

```python
# –ü—Ä–æ–±–ª–µ–º–∞: ChromeDriver –Ω–µ –Ω–∞–π–¥–µ–Ω
def fix_chromedriver_issue():
    """–†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Å ChromeDriver"""
    try:
        from webdriver_manager.chrome import ChromeDriverManager
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ ChromeDriver: {e}")
        # –†—É—á–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞
        print("–°–∫–∞—á–∞–π—Ç–µ ChromeDriver —Å https://chromedriver.chromium.org/")
        print("–î–æ–±–∞–≤—å—Ç–µ –≤ PATH –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –≤ –∫–æ–¥–µ")

# –ü—Ä–æ–±–ª–µ–º–∞: –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —Å–∞–π—Ç–∞–º–∏
def fix_blocking_issue():
    """–†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Å –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π"""
    options = ChromeOptions()
    options.add_argument("--headless=new")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)

    # –†–æ—Ç–∞—Ü–∏—è User-Agent
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
    ]
    import random
    options.add_argument(f"--user-agent={random.choice(user_agents)}")
```

#### 2. –û—à–∏–±–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

```python
# –ü—Ä–æ–±–ª–µ–º–∞: –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ë–î
def fix_database_lock():
    """–†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Å –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π –ë–î"""
    import sqlite3

    try:
        conn = sqlite3.connect("serp_tracker.db", timeout=20)
        conn.execute("PRAGMA journal_mode=WAL")
        conn.execute("PRAGMA synchronous=NORMAL")
        conn.execute("PRAGMA cache_size=10000")
        conn.execute("PRAGMA temp_store=MEMORY")
    except sqlite3.OperationalError as e:
        print(f"–û—à–∏–±–∫–∞ –ë–î: {e}")
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
        import shutil
        shutil.copy2("serp_tracker.db", "serp_tracker_backup.db")

# –ü—Ä–æ–±–ª–µ–º–∞: –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–µ –ë–î
def fix_corrupted_database():
    """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–æ–π –ë–î"""
    import sqlite3

    try:
        conn = sqlite3.connect("serp_tracker.db")
        conn.execute("PRAGMA integrity_check")
    except sqlite3.DatabaseError:
        print("–ë–î –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞, –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º...")

        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
        import shutil
        if os.path.exists("serp_tracker_backup.db"):
            shutil.copy2("serp_tracker_backup.db", "serp_tracker.db")
        else:
            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –ë–î
            init_database()
```

#### 3. –û—à–∏–±–∫–∏ –ø–∞–º—è—Ç–∏

```python
# –ü—Ä–æ–±–ª–µ–º–∞: –£—Ç–µ—á–∫–∞ –ø–∞–º—è—Ç–∏
def fix_memory_leak():
    """–†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Å –ø–∞–º—è—Ç—å—é"""
    import gc

    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
    gc.collect()

    # –ó–∞–∫—Ä—ã—Ç–∏–µ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
    if 'driver' in globals():
        driver.quit()

    # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    import tempfile
    import os
    temp_dir = tempfile.gettempdir()
    for file in os.listdir(temp_dir):
        if file.startswith("scrapinghub"):
            os.remove(os.path.join(temp_dir, file))
```

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫

```python
import logging
import traceback
from datetime import datetime

def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('seo_log.txt'),
            logging.StreamHandler()
        ]
    )

def log_error(error, context=""):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫"""
    logger = logging.getLogger(__name__)

    error_info = {
        'timestamp': datetime.now().isoformat(),
        'error_type': type(error).__name__,
        'error_message': str(error),
        'traceback': traceback.format_exc(),
        'context': context
    }

    logger.error(f"–û—à–∏–±–∫–∞: {error_info}")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    with open('error_log.json', 'a') as f:
        json.dump(error_info, f)
        f.write('\n')
```

---

## üöÄ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é

### 1. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

#### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è WebDriver

```python
def optimize_webdriver():
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ WebDriver"""
    options = ChromeOptions()

    # –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ–Ω—É–∂–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-software-rasterizer")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-background-networking")
    options.add_argument("--disable-background-timer-throttling")
    options.add_argument("--disable-backgrounding-occluded-windows")
    options.add_argument("--disable-renderer-backgrounding")

    # –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
    prefs = {
        "profile.default_content_setting_values.images": 2,
        "profile.managed_default_content_settings.images": 2
    }
    options.add_experimental_option("prefs", prefs)

    return options
```

#### –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```python
import hashlib
import pickle
import os

class CacheManager:
    def __init__(self, cache_dir="cache"):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)

    def get_cache_key(self, url, analysis_type):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫—ç—à–∞"""
        content = f"{url}_{analysis_type}"
        return hashlib.md5(content.encode()).hexdigest()

    def get_cached_result(self, url, analysis_type):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–∑ –∫—ç—à–∞"""
        cache_key = self.get_cache_key(url, analysis_type)
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.pkl")

        if os.path.exists(cache_file):
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ (24 —á–∞—Å–∞)
            if time.time() - os.path.getmtime(cache_file) < 86400:
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)

        return None

    def save_to_cache(self, url, analysis_type, result):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –∫—ç—à"""
        cache_key = self.get_cache_key(url, analysis_type)
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.pkl")

        with open(cache_file, 'wb') as f:
            pickle.dump(result, f)
```

### 2. –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å

#### –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å

```python
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

def analyze_multiple_sites(sites_list, max_workers=5):
    """–ê–Ω–∞–ª–∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–∞–π—Ç–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ"""
    results = {}

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á
        future_to_site = {
            executor.submit(analyze_single_site, site): site
            for site in sites_list
        }

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        for future in as_completed(future_to_site):
            site = future_to_site[future]
            try:
                result = future.result()
                results[site] = result
            except Exception as e:
                results[site] = {'error': str(e)}

    return results

def analyze_single_site(site_url):
    """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Å–∞–π—Ç–∞"""
    # –õ–æ–≥–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
    return {'url': site_url, 'status': 'completed'}
```

#### –û—á–µ—Ä–µ–¥–∏ –∑–∞–¥–∞—á

```python
import queue
import threading
import time

class TaskQueue:
    def __init__(self, max_workers=3):
        self.task_queue = queue.Queue()
        self.result_queue = queue.Queue()
        self.workers = []
        self.max_workers = max_workers
        self.running = True

        # –ó–∞–ø—É—Å–∫ –≤–æ—Ä–∫–µ—Ä–æ–≤
        for _ in range(max_workers):
            worker = threading.Thread(target=self._worker)
            worker.daemon = True
            worker.start()
            self.workers.append(worker)

    def _worker(self):
        """–í–æ—Ä–∫–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á"""
        while self.running:
            try:
                task = self.task_queue.get(timeout=1)
                result = self._process_task(task)
                self.result_queue.put(result)
                self.task_queue.task_done()
            except queue.Empty:
                continue

    def _process_task(self, task):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏"""
        task_type = task.get('type')

        if task_type == 'seo_analysis':
            return self._analyze_seo(task['url'])
        elif task_type == 'serp_tracking':
            return self._track_serp(task['keyword'], task['domain'])
        else:
            return {'error': 'Unknown task type'}

    def add_task(self, task):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –≤ –æ—á–µ—Ä–µ–¥—å"""
        self.task_queue.put(task)

    def get_result(self, timeout=None):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        return self.result_queue.get(timeout=timeout)

    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—á–µ—Ä–µ–¥–∏"""
        self.running = False
        for worker in self.workers:
            worker.join()
```

### 3. –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

#### –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

```python
import re
from urllib.parse import urlparse

def validate_url(url):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è URL"""
    if not url:
        return False, "URL –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
    if not re.match(r'^https?://', url):
        return False, "URL –¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å http:// –∏–ª–∏ https://"

    # –ü–∞—Ä—Å–∏–Ω–≥ URL
    try:
        parsed = urlparse(url)
        if not parsed.netloc:
            return False, "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –¥–æ–º–µ–Ω"
    except Exception:
        return False, "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç URL"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã
    if len(url) > 2048:
        return False, "URL —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π"

    return True, "URL –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω"

def sanitize_input(text):
    """–û—á–∏—Å—Ç–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    if not text:
        return ""

    # –£–¥–∞–ª–µ–Ω–∏–µ –æ–ø–∞—Å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
    dangerous_chars = ['<', '>', '"', "'", '&']
    for char in dangerous_chars:
        text = text.replace(char, '')

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã
    if len(text) > 1000:
        text = text[:1000]

    return text.strip()
```

#### –ó–∞—â–∏—Ç–∞ –æ—Ç –∞—Ç–∞–∫

```python
import hashlib
import secrets

class SecurityManager:
    def __init__(self):
        self.salt = secrets.token_hex(16)

    def hash_sensitive_data(self, data):
        """–•–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if not data:
            return None

        # –°–æ–∑–¥–∞–Ω–∏–µ —Ö–µ—à–∞ —Å —Å–æ–ª—å—é
        salted_data = data + self.salt
        return hashlib.sha256(salted_data.encode()).hexdigest()

    def validate_api_key(self, api_key):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è API –∫–ª—é—á–∞"""
        if not api_key:
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
        if not re.match(r'^[A-Za-z0-9]{32,}$', api_key):
            return False

        return True

    def rate_limit(self, ip_address, action, limit=100):
        """–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤"""
        import time

        current_time = time.time()
        key = f"{ip_address}_{action}"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)
        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Redis –∏–ª–∏ –ø–æ–¥–æ–±–Ω–æ–µ
        return True
```

### 4. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

#### –°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

```python
import psutil
import time
from datetime import datetime

class SystemMonitor:
    def __init__(self):
        self.metrics = []

    def collect_metrics(self):
        """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ —Å–∏—Å—Ç–µ–º—ã"""
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_usage': psutil.disk_usage('/').percent,
            'network_io': psutil.net_io_counters()._asdict()
        }

        self.metrics.append(metrics)

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏
        if len(self.metrics) > 1000:
            self.metrics = self.metrics[-1000:]

        return metrics

    def get_alerts(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π"""
        alerts = []

        if len(self.metrics) == 0:
            return alerts

        latest = self.metrics[-1]

        if latest['cpu_percent'] > 80:
            alerts.append("–í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU")

        if latest['memory_percent'] > 85:
            alerts.append("–í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏")

        if latest['disk_usage'] > 90:
            alerts.append("–ú–∞–ª–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ")

        return alerts

    def generate_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        if len(self.metrics) == 0:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á–µ—Ç–∞"

        avg_cpu = sum(m['cpu_percent'] for m in self.metrics) / len(self.metrics)
        avg_memory = sum(m['memory_percent'] for m in self.metrics) / len(self.metrics)

        return {
            'period': f"{self.metrics[0]['timestamp']} - {self.metrics[-1]['timestamp']}",
            'avg_cpu': round(avg_cpu, 2),
            'avg_memory': round(avg_memory, 2),
            'total_metrics': len(self.metrics)
        }
```

### 5. –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è

#### –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–¥–∞—á

```python
import schedule
import time
import threading

class TaskScheduler:
    def __init__(self):
        self.running = False
        self.thread = None

    def start(self):
        """–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
        self.running = True
        self.thread = threading.Thread(target=self._run_scheduler)
        self.thread.daemon = True
        self.thread.start()

    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
        self.running = False
        if self.thread:
            self.thread.join()

    def _run_scheduler(self):
        """–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        while self.running:
            schedule.run_pending()
            time.sleep(1)

    def schedule_daily_analysis(self, sites_list, time="09:00"):
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        schedule.every().day.at(time).do(self._run_daily_analysis, sites_list)

    def schedule_serp_tracking(self, keywords_list, domain, time="10:00"):
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π"""
        schedule.every().day.at(time).do(self._run_serp_tracking, keywords_list, domain)

    def _run_daily_analysis(self, sites_list):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        print(f"–ó–∞–ø—É—Å–∫ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è {len(sites_list)} —Å–∞–π—Ç–æ–≤")
        # –õ–æ–≥–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞

    def _run_serp_tracking(self, keywords_list, domain):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π"""
        print(f"–ó–∞–ø—É—Å–∫ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –¥–æ–º–µ–Ω–∞ {domain}")
        # –õ–æ–≥–∏–∫–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞
```

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

### –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Selenium](https://selenium-python.readthedocs.io/)
- [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Flet](https://flet.dev/docs/)
- [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Pandas](https://pandas.pydata.org/docs/)
- [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è SQLite](https://www.sqlite.org/docs.html)

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã

- **PyCharm** - IDE –¥–ª—è Python —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
- **Postman** - —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ API
- **SQLite Browser** - –ø—Ä–æ—Å–º–æ—Ç—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
- **Chrome DevTools** - –æ—Ç–ª–∞–¥–∫–∞ –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥–∞

### –°—Ç–∞–Ω–¥–∞—Ä—Ç—ã –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è

- **PEP 8** - —Å—Ç–∏–ª—å –∫–æ–¥–∞ Python
- **PEP 257** - –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- **Type Hints** - —Ç–∏–ø–∏–∑–∞—Ü–∏—è –∫–æ–¥–∞

---

## ü§ù –ü–æ–¥–¥–µ—Ä–∂–∫–∞

### –ö–æ–Ω—Ç–∞–∫—Ç—ã –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤

- **Email**: developer@seo-analyzer.com
- **GitHub Issues**: https://github.com/username/seo-analyzer/issues
- **Discord**: https://discord.gg/seo-analyzer

### –ü—Ä–æ—Ü–µ—Å—Å –≤–Ω–µ—Å–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π

1. –°–æ–∑–¥–∞–π—Ç–µ issue —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –ø—Ä–æ–±–ª–µ–º—ã/—É–ª—É—á—à–µ–Ω–∏—è
2. –§–æ—Ä–∫–Ω–∏—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
3. –°–æ–∑–¥–∞–π—Ç–µ feature branch
4. –í–Ω–µ—Å–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å —Ç–µ—Å—Ç–∞–º–∏
5. –°–æ–∑–¥–∞–π—Ç–µ Pull Request
6. –î–æ–∂–¥–∏—Ç–µ—Å—å code review
7. –ü–æ—Å–ª–µ –æ–¥–æ–±—Ä–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –±—É–¥—É—Ç —Å–ª–∏—Ç—ã

---

**–£–¥–∞—á–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏! üöÄ**
